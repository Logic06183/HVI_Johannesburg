install.packages("GWmodel")
install.packages("rgdal")
install.packages("sp")
library(readxl)
data <- read_excel("C:/Users/CraigParker/OneDrive - Wits PHR/Desktop/HVI_Johannesburg/data.csv")
library(GWmodel)
library(rgdal)
install.packages("rgdal")
library(sp)
data <- read.csv('C:\Users\CraigParker\OneDrive - Wits PHR\Desktop\HVI_Johannesburg\data.csv')
setwd("C:/Users/CraigParker/OneDrive - Wits PHR/Desktop/HVI_Johannesburg")
library(GWmodel)
library(rgdal)
install.packages("sf")
data <- read.csv("C:/Users/CraigParker/OneDrive - Wits PHR/Desktop/HVI_Johannesburg/data.csv", header=FALSE)
View(data)
load("C:/Users/CraigParker/OneDrive - Wits PHR/Desktop/HVI_Johannesburg/geometry.shp")
library(sf)
# Load shapefile (adjust the path as needed)
shapefile_path <- "C:/Users/CraigParker/OneDrive - Wits PHR/Desktop/HVI_Johannesburg/your_shapefile.shp"
geometry <- st_read(shapefile_path)
shapefile_path <- "C:/Users/CraigParker/OneDrive - Wits PHR/Desktop/HVI_Johannesburg/your_shapefile.shp"
geometry <- st_read(shapefile_path)
# Load shapefile (adjust the path as needed)
shapefile_path <- "geometry.shp"
geometry <- st_read(shapefile_path)
library(GWmodel)
library(sp)
# Load shapefile (adjust the path as needed)
shapefile_path <- "geometry.shp"
geometry <- st_read(shapefile_path)
# Step 3: Merge the attribute data and spatial data
# Assuming you have a common key column, e.g., "id" in both datasets
# Make sure your column names align in both datasets
merged_data <- merge(geometry, data, by = "id")
View(geometry)
View(data)
# Check column names for both datasets
names(geometry)
names(data)
# Read attribute data
data <- read.csv('data.csv,header = TRUE)
geometry <- readOGR(dsn = ".", layer = "geometry")
names(geometry)
names(data)
View(data)
View(data)
names(data)
View(data)
View(data)
data <- read.csv('data.csv,header = TRUE)
data <- read.csv('data.csv',header = TRUE)
geometry <- readOGR(dsn = ".", layer = "geometry")
shapefile_path <- "geometry.shp"
geometry <- st_read(shapefile_path)
names(geometry)
names(data)
merged_data <- merge(geometry, data, by = "WardID_")
names(merged_data)
# Load dplyr for easier column selection
library(dplyr)
install.packages("dplyr")
library(dplyr)
cleaned_data <- merged_data %>%
select(-ends_with(".y"))
names(cleaned_data)
names(cleaned_data) <- gsub("\\.x$", "", names(cleaned_data))
names(cleaned_data)
cleaned_data_sp <- as(cleaned_data, "Spatial")
vars <- names(cleaned_data_sp)[c(4:21)]
library(GWmodel)
gwpca_result <- gwpca(cleaned_data_sp, vars = vars, bw = 100, robust = TRUE)
summary(gwpca_result)
plot(gwpca_result)
local_pv <- gwpca_result$local.PV[, 1]
cleaned_data_sp@data$local_pv <- local_pv
spplot(cleaned_data_sp, "local_pv", main = "Explained Variance: First Principal Component")
source("~/.active-rstudio-document")
library(GWmodel)
library(sp)
library(sf)
library(dplyr)
# Read attribute data
data <- read.csv('data.csv', header = TRUE)
# Load shapefile
shapefile_path <- "geometry.shp"
geometry <- st_read(shapefile_path)
# Project the geometry to a suitable CRS (e.g., UTM Zone 35S)
geometry <- st_transform(geometry, crs = 32735)
# Merge datasets
merged_data <- merge(geometry, data, by = "WardID_")
# Remove duplicate columns and clean names
cleaned_data <- merged_data %>%
select(-ends_with(".y"))
names(cleaned_data) <- gsub("\\.x$", "", names(cleaned_data))
# Convert to Spatial object
cleaned_data_sp <- as(cleaned_data, "Spatial")
# Define variables
vars <- c(
"Crowded dwellings", "No piped water", "Using public healthcare facilities", "Poor health status",
"Failed to find healthcare when needed", "No medical insurance", "Household hunger risk",
"Benefiting from school feeding scheme", "UTFVI", "LST", "NDVI", "NDBI__mean", "concern_he",
"cancer_pro", "diabetes_p", "pneumonia_", "heart_dise", "hypertensi", "hiv_prop", "tb_prop",
"covid_prop", "60_plus_pr"
)
# Ensure variables exist
missing_vars <- setdiff(vars, names(cleaned_data_sp@data))
if (length(missing_vars) > 0) {
stop(paste("The following variables are missing:", paste(missing_vars, collapse = ", ")))
# Check for missing values
if (any(is.na(cleaned_data_sp@data[vars]))) {
stop("There are missing values in the variables. Please handle them before proceeding.")
}
# Determine optimal bandwidth
bw <- bw.gwpca(cleaned_data_sp, vars = vars, k = 2, robust = TRUE)
# Perform GWPCA
gwpca_result <- gwpca(cleaned_data_sp, vars = vars, bw = bw, k = 2, robust = TRUE)
# View summary
summary(gwpca_result)
# Extract local explained variance for PC1
local_pv <- sapply(gwpca_result$local.eval, function(x) x[1]) / gwpca_result$tot.var * 100
# Add to spatial data
cleaned_data_sp@data$local_pv <- local_pv
# Plot explained variance
spplot(cleaned_data_sp, "local_pv", main = "Explained Variance: First Principal Component")
source("~/.active-rstudio-document")
if (any(is.na(cleaned_data_sp@data[vars]))) {
stop("There are missing values in the variables. Please handle them before proceeding.")
}
View(gwpca_result)
summary(gwpca_result)
source("C:/Users/CraigParker/OneDrive - Wits PHR/Desktop/HVI_Johannesburg/GWPCA.R")
library(GWmodel)
library(sp)
library(sf)
library(dplyr)
data <- read.csv('data.csv', header = TRUE)
shapefile_path <- "geometry.shp"
geometry <- st_read(shapefile_path)
geometry <- st_transform(geometry, crs = 32735)
merged_data <- merge(geometry, data, by = "WardID_")
cleaned_data <- merged_data %>%
select(-ends_with(".y"))
names(cleaned_data) <- gsub("\\.x$", "", names(cleaned_data))
cleaned_data_sp <- as(cleaned_data, "Spatial")
vars <- c(
"Crowded dwellings", "No piped water", "Using public healthcare facilities", "Poor health status",
"Failed to find healthcare when needed", "No medical insurance", "Household hunger risk",
"Benefiting from school feeding scheme", "UTFVI", "LST", "NDVI", "NDBI__mean", "concern_he",
"cancer_pro", "diabetes_p", "pneumonia_", "heart_dise", "hypertensi", "hiv_prop", "tb_prop",
"covid_prop", "60_plus_pr"
)
missing_vars <- setdiff(vars, names(cleaned_data_sp@data))
if (length(missing_vars) > 0) {
stop(paste("The following variables are missing:", paste(missing_vars, collapse = ", ")))
}
View(cleaned_data_sp)
# List all column names in your data frame
names(cleaned_data_sp@data)
# List all column names in your data frame
names(cleaned_data_sp@data)
# Use make.names to create syntactically valid names
names(cleaned_data_sp@data) <- make.names(names(cleaned_data_sp@data))
# Alternatively, replace spaces with underscores
names(cleaned_data_sp@data) <- gsub(" ", "_", names(cleaned_data_sp@data))
# View updated column names
names(cleaned_data_sp@data)
# View updated column names
names(cleaned_data_sp@data)
# Apply the same transformation to vars
vars <- make.names(vars)
# Or replace spaces with underscores
vars <- gsub(" ", "_", vars)
# View updated vars
print(vars)
# Check which variables are missing after standardization
missing_vars <- setdiff(vars, names(cleaned_data_sp@data))
if (length(missing_vars) > 0) {
warning(paste("The following variables are still missing:", paste(missing_vars, collapse = ", ")))
} else {
print("All variables are present.")
}
# Check for missing values
if (any(is.na(cleaned_data_sp@data[vars]))) {
stop("There are missing values in the variables. Please handle them before proceeding.")
}
# Determine optimal bandwidth
bw <- bw.gwpca(cleaned_data_sp, vars = vars, k = 2, robust = TRUE)
# Extract local explained variance for PC1
local_pv <- sapply(gwpca_result$local.eval, function(x) x[1]) / gwpca_result$tot.var * 100
cleaned_data_sp@data$local_pv <- local_pv
# Plot explained variance
spplot(cleaned_data_sp, "local_pv", main = "Explained Variance: First Principal Component")
source("C:/Users/CraigParker/OneDrive - Wits PHR/Desktop/HVI_Johannesburg/GWPCA.R")
